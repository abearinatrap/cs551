{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: tpot in ./venv/lib/python3.11/site-packages (0.12.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in ./venv/lib/python3.11/site-packages (from tpot) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./venv/lib/python3.11/site-packages (from tpot) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in ./venv/lib/python3.11/site-packages (from tpot) (1.3.2)\n",
      "Requirement already satisfied: deap>=1.2 in ./venv/lib/python3.11/site-packages (from tpot) (1.4.1)\n",
      "Requirement already satisfied: update-checker>=0.16 in ./venv/lib/python3.11/site-packages (from tpot) (0.18.0)\n",
      "Requirement already satisfied: tqdm>=4.36.1 in ./venv/lib/python3.11/site-packages (from tpot) (4.66.1)\n",
      "Requirement already satisfied: stopit>=1.1.1 in ./venv/lib/python3.11/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: pandas>=0.24.2 in ./venv/lib/python3.11/site-packages (from tpot) (2.1.3)\n",
      "Requirement already satisfied: joblib>=0.13.2 in ./venv/lib/python3.11/site-packages (from tpot) (1.3.2)\n",
      "Requirement already satisfied: xgboost>=1.1.0 in ./venv/lib/python3.11/site-packages (from tpot) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.11/site-packages (from pandas>=0.24.2->tpot) (2023.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.11/site-packages (from scikit-learn>=0.22.0->tpot) (3.2.0)\n",
      "Requirement already satisfied: requests>=2.3.0 in ./venv/lib/python3.11/site-packages (from update-checker>=0.16->tpot) (2.31.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->tpot) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.11/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install tpot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder  \n",
    "from tpot import TPOTClassifier\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
      "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
      "      dtype='object')\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "PassengerId      0.000000\n",
      "Survived         0.000000\n",
      "Pclass           0.000000\n",
      "Name             0.000000\n",
      "Sex              0.000000\n",
      "Age             24.789916\n",
      "SibSp            0.000000\n",
      "Parch            0.000000\n",
      "Ticket           0.000000\n",
      "Fare             0.000000\n",
      "Cabin          336.764706\n",
      "Embarked         0.224972\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(train_data.columns)\n",
    "print(train_data.head())\n",
    "\n",
    "# print which columns have missing data\n",
    "print(100*train_data.isnull().sum()/train_data.count())\n",
    "\n",
    "# remove cabin, name: useless\n",
    "train_data = train_data.drop(['Cabin', 'Name'],axis = 1)\n",
    "\n",
    "# fill missing age data with mean value\n",
    "mean_age = train_data['Age'].mean()\n",
    "train_data['Age'].fillna(mean_age, inplace=True)\n",
    "\n",
    "# remove ticket information: cant use this text information\n",
    "train_data = train_data.drop(['Ticket'],axis = 1)\n",
    "\n",
    "y = train_data['Survived'] \n",
    "X = train_data.drop('Survived',axis =1)\n",
    "\n",
    "le = LabelEncoder()\n",
    "for column in ['Sex', 'Embarked']:\n",
    "    X[column] = le.fit_transform(train_data[column])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
      "0            1       3    1  22.0      1      0   7.2500         2\n",
      "1            2       1    0  38.0      1      0  71.2833         0\n",
      "2            3       3    0  26.0      0      0   7.9250         2\n",
      "3            4       1    0  35.0      1      0  53.1000         2\n",
      "4            5       3    1  35.0      0      0   8.0500         2\n"
     ]
    }
   ],
   "source": [
    "print(X.head())\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                               \n",
      "Generation 1 - Current best internal CV score: 0.8286023835319611\n",
      "                                                                               \n",
      "Generation 2 - Current best internal CV score: 0.8286023835319611\n",
      "                                                                               \n",
      "Generation 3 - Current best internal CV score: 0.8286023835319611\n",
      "                                                                               \n",
      "Generation 4 - Current best internal CV score: 0.8286023835319611\n",
      "                                                                               \n",
      "Generation 5 - Current best internal CV score: 0.8300206835418104\n",
      "                                                                               \n",
      "Generation 6 - Current best internal CV score: 0.8300206835418104\n",
      "                                                                               \n",
      "Generation 7 - Current best internal CV score: 0.8300206835418104\n",
      "                                                                               \n",
      "Generation 8 - Current best internal CV score: 0.8300206835418104\n",
      "                                                                                \n",
      "Generation 9 - Current best internal CV score: 0.8300206835418104\n",
      "                                                                                \n",
      "Generation 10 - Current best internal CV score: 0.8300206835418104\n",
      "                                                                                \n",
      "Best pipeline: RandomForestClassifier(MaxAbsScaler(input_matrix), bootstrap=True, criterion=entropy, max_features=0.4, min_samples_leaf=1, min_samples_split=15, n_estimators=100)\n",
      "Accuracy: 0.8156424581005587\n",
      "F1 Score: 0.762589928057554\n",
      "Confusion Matrix:\n",
      "[[93 12]\n",
      " [21 53]]\n",
      "--- 326.7645628452301 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "tpot_classifier = TPOTClassifier(generations=10, population_size=100, random_state=42, verbosity=2, scoring='accuracy', cv=5)\n",
    "tpot_classifier.fit(X_train, y_train)\n",
    "\n",
    "# predict on test\n",
    "y_pred = tpot_classifier.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8212290502793296\n",
      "F1 Score: 0.7714285714285715\n",
      "Confusion Matrix:\n",
      "[[93 12]\n",
      " [20 54]]\n"
     ]
    }
   ],
   "source": [
    "random_forest_classifier = RandomForestClassifier(n_estimators=37, max_depth=10, random_state=42)\n",
    "random_forest_classifier.fit(X_train, y_train)\n",
    "\n",
    "# pred on ptest\n",
    "y_pred = random_forest_classifier.predict(X_val)\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "f1 = f1_score(y_val, y_pred)\n",
    "conf_matrix = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
